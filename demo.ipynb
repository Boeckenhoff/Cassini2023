{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bef228-ea45-4867-91b8-916cae0caad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.26.1)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.11.3 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564439e5-4b08-43fc-a77c-2ebf3f3c0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import getpass\n",
    "from sentinelhub import (\n",
    "    SHConfig,\n",
    "    DataCollection,\n",
    "    SentinelHubCatalog,\n",
    "    SentinelHubRequest,\n",
    "    SentinelHubStatistical,\n",
    "    BBox,\n",
    "    bbox_to_dimensions,\n",
    "    CRS,\n",
    "    MimeType,\n",
    "    Geometry,\n",
    ")\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2a98f0-fee4-481d-a67d-c1df723a3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Load your data\n",
    "def inference(df):\n",
    "    X = df[['ndvi_mean', 'ndwi_mean', 'avg_elevation']]\n",
    "    with open('scaler.pkl', 'rb') as file:\n",
    "        scaler = pickle.load(file)\n",
    "    X = scaler.transform(X)\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    y_pred_probs = model.predict_proba(X)[:, 1]\n",
    "    return y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fcc0cc-cbe9-42ea-a772-fd731a2b4a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "sh-45e9da6d-83d3-4b94-863f-fdfbf42353ac ········\n",
      "1psSm3NyziCaifLzZKsFBOjLFqMlzIHx ········\n"
     ]
    }
   ],
   "source": [
    "config = SHConfig()\n",
    "config.sh_client_id = getpass.getpass(\"sh-45e9da6d-83d3-4b94-863f-fdfbf42353ac\")\n",
    "config.sh_client_secret = getpass.getpass(\"1psSm3NyziCaifLzZKsFBOjLFqMlzIHx\")\n",
    "config.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "config.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n",
    "# config.save(\"cdse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e4904b-f5af-4c50-b386-2cc501a68e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to extract statistics for all acquisition dates\n",
    "def extract_stats(date, stat_data):\n",
    "    d = {}\n",
    "    for key, value in stat_data[\"outputs\"].items():\n",
    "        stats = value[\"bands\"][\"B0\"][\"stats\"]\n",
    "        if stats[\"sampleCount\"] == stats[\"noDataCount\"]:\n",
    "            continue\n",
    "        else:\n",
    "            d[\"date\"] = [date]\n",
    "            for stat_name, stat_value in stats.items():\n",
    "                if stat_name == \"sampleCount\" or stat_name == \"noDataCount\":\n",
    "                    continue\n",
    "                else:\n",
    "                    d[f\"{key}_{stat_name}\"] = [stat_value]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "def read_acquisitions_stats(stat_data):\n",
    "    df_li = []\n",
    "    for aq in stat_data:\n",
    "        date = aq[\"interval\"][\"from\"][:10]\n",
    "        df_li.append(extract_stats(date, aq))\n",
    "    return pd.concat(df_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ae346b-16f7-4b9f-a5c4-ede9ed432553",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_ndvi = \"\"\"\n",
    "//VERSION=3\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [{\n",
    "      bands: [\n",
    "        \"B04\",\n",
    "        \"B08\",\n",
    "        \"dataMask\"\n",
    "      ]\n",
    "    }],\n",
    "    output: [\n",
    "      {\n",
    "        id: \"ndvi\",\n",
    "        bands: 1\n",
    "      },\n",
    "      {\n",
    "        id: \"dataMask\",\n",
    "        bands: 1\n",
    "      }]\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "    let index = (samples.B08 - samples.B04) / (samples.B08+samples.B04);\n",
    "    return {\n",
    "        ndvi: [index],\n",
    "        dataMask: [samples.dataMask],\n",
    "    };\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "evalscript_ndwi = \"\"\"\n",
    "//VERSION=3\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [{\n",
    "      bands: [\n",
    "        \"B03\", // Green band\n",
    "        \"B08\", // NIR band\n",
    "        \"dataMask\" // Mask to exclude the non-valid pixels\n",
    "      ]\n",
    "    }],\n",
    "    output: [\n",
    "      {\n",
    "        id: \"ndwi\",\n",
    "        bands: 1,\n",
    "        sampleType: \"FLOAT32\"\n",
    "      },\n",
    "      {\n",
    "        id: \"dataMask\",\n",
    "        bands: 1\n",
    "      }\n",
    "    ]\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(samples) {\n",
    "    let ndwi = (samples.B03 - samples.B08) / (samples.B03 + samples.B08);\n",
    "    return {\n",
    "        ndwi: [ndwi],\n",
    "        dataMask: [samples.dataMask],\n",
    "    };\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c22a13-de5a-42ed-87fc-78f5501b0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_request(geojson_data):\n",
    "    geometry = geojson_data['geometry']\n",
    "    def get_open_elevation(lat, lon):\n",
    "        query = f'https://api.open-elevation.com/api/v1/lookup?locations={lat},{lon}'\n",
    "        response = requests.get(query).json()\n",
    "        # Check if the response contains results\n",
    "        if 'results' in response:\n",
    "            return response['results'][0]['elevation']\n",
    "        else:\n",
    "            return 270.0\n",
    "    a = get_open_elevation(*geometry['coordinates'][0][0]) \n",
    "    \n",
    "    # Create a Geometry object for the Sentinel Hub request\n",
    "    polygon_geometry = Geometry(geometry=geometry, crs=CRS.WGS84)\n",
    "\n",
    "    request_ndvi = SentinelHubStatistical(\n",
    "        aggregation=SentinelHubStatistical.aggregation(\n",
    "            evalscript=evalscript_ndvi,\n",
    "            time_interval=(\"2020-01-01T00:00:00Z\", \"2020-12-30T23:59:59Z\"),\n",
    "            aggregation_interval=\"P1D\",\n",
    "            size=[200, 200],\n",
    "\n",
    "        ),\n",
    "        input_data=[\n",
    "            SentinelHubStatistical.input_data(\n",
    "                DataCollection.SENTINEL2_L1C.define_from(\n",
    "                    name=\"s2l1c\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
    "                ),\n",
    "                other_args={\"dataFilter\": {\"maxCloudCoverage\": 10}},\n",
    "            ),\n",
    "        ],\n",
    "        geometry=polygon_geometry,\n",
    "        config=config,\n",
    "    )\n",
    "    request_ndwi = SentinelHubStatistical(\n",
    "        aggregation=SentinelHubStatistical.aggregation(\n",
    "            evalscript=evalscript_ndwi,\n",
    "            time_interval=(\"2020-01-01T00:00:00Z\", \"2020-12-30T23:59:59Z\"),\n",
    "            aggregation_interval=\"P1D\",\n",
    "            size=[200, 200],\n",
    "        ),\n",
    "        input_data=[\n",
    "            SentinelHubStatistical.input_data(\n",
    "                DataCollection.SENTINEL2_L1C.define_from(\n",
    "                    name=\"s2l1c\", service_url=\"https://sh.dataspace.copernicus.eu\"\n",
    "                ),\n",
    "                other_args={\"dataFilter\": {\"maxCloudCoverage\": 10}},\n",
    "            ),\n",
    "        ],\n",
    "        geometry=polygon_geometry,\n",
    "        config=config,\n",
    "    )\n",
    "    response_ndvi = request_ndvi.get_data()\n",
    "    response_ndwi = request_ndwi.get_data()\n",
    "    # result_ndvi = read_acquisitions_stats(response_ndvi[0][\"data\"])\n",
    "    # result_ndwi = read_acquisitions_stats(response_ndwi[0][\"data\"])\n",
    "    # Assume response_ndvi and response_ndwi are now populated with data\n",
    "    # Convert results to DataFrame\n",
    "    df_ndvi = pd.DataFrame(read_acquisitions_stats(response_ndvi[0]['data']))\n",
    "    df_ndwi = pd.DataFrame(read_acquisitions_stats(response_ndwi[0]['data']))\n",
    "\n",
    "    # Convert the 'date' column to datetime format to ease processing\n",
    "    df_ndvi['date'] = pd.to_datetime(df_ndvi['date'])\n",
    "    df_ndwi['date'] = pd.to_datetime(df_ndwi['date'])\n",
    "\n",
    "    # Group by year and calculate the mean of the means for each year\n",
    "    yearly_ndvi = df_ndvi.groupby(df_ndvi['date'].dt.year)['ndvi_mean'].mean().reset_index()\n",
    "    yearly_ndwi = df_ndwi.groupby(df_ndwi['date'].dt.year)['ndwi_mean'].mean().reset_index()\n",
    "\n",
    "    # Combine the yearly means into a single dataframe\n",
    "    yearly_combined = pd.merge(yearly_ndvi, yearly_ndwi, on='date', how='outer', suffixes=('_ndvi', '_ndwi'))\n",
    "\n",
    "    yearly_combined['avg_elevation'] = a  # Assuming average_elevations list is already populated\n",
    "\n",
    "    # Rename the columns to reflect the data correctly\n",
    "    yearly_combined.rename(columns={'date': 'year'}, inplace=True)\n",
    "\n",
    "    return yearly_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ebc63b-719c-4f15-a9d4-7cc78e5a8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai(geo_json):\n",
    "    datapoint_df = api_request(geo_json)\n",
    "    probability = inference(datapoint_df)\n",
    "    #normalize           \n",
    "    #lg.regression predict\n",
    "    return probability[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a420d023-6c83-433f-8a5b-f49fd9db5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_color(value):\n",
    "    if not (0 <= value <= 1):\n",
    "        raise ValueError(\"Value must be within [0, 1].\")\n",
    "\n",
    "    # Linearly interpolate between green (0,255,0) and red (255,0,0)\n",
    "    red = int(255 * value)\n",
    "    green = int(255 * (1 - value))\n",
    "    blue = 0  # No blue component\n",
    "    \n",
    "    return '#{:02X}{:02X}{:02X}'.format(red, green, blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f770dfa-6044-4fed-82ce-4465637d79a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9da2fbd562c4b63b5d6cccd4f344436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[41.3874, 2.1686], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoo…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyleaflet import Map, DrawControl, GeoJSON\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Function to generate a random color in hexadecimal format\n",
    "def random_color():\n",
    "    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n",
    "\n",
    "# Create a Map instance\n",
    "m = Map(center=(41.3874, 2.1686), zoom=4)\n",
    "\n",
    "# Create a DrawControl instance\n",
    "draw_control = DrawControl()\n",
    "\n",
    "# Only allow Polygon drawing\n",
    "draw_control.polygon = {\n",
    "    \"shapeOptions\": {\n",
    "        \"fillOpacity\": 0.8,\n",
    "        \"color\": \"#333333\"  # Default color, will be overridden by random color\n",
    "    },\n",
    "    \"allowIntersection\": False\n",
    "}\n",
    "draw_control.polyline = {}\n",
    "draw_control.circlemarker = {}\n",
    "draw_control.rectangle = {}\n",
    "draw_control.circle = {}\n",
    "draw_control.marker = {}\n",
    "\n",
    "def handle_draw(target, action, geo_json):\n",
    "    # When a polygon is created, set its color to a random value\n",
    "    if action == 'created':\n",
    "        print(geo_json)\n",
    "        risk = ai(geo_json)\n",
    "        color = float_to_color(risk)\n",
    "        style = {\n",
    "            'fillColor': color,\n",
    "            'weight': 1,\n",
    "            'color': color\n",
    "        }\n",
    "        geo_json['properties']['style'] = style\n",
    "        geo_layer = GeoJSON(data=geo_json, style=style)\n",
    "        m.add_layer(geo_layer)\n",
    "        # save\n",
    "        file_path = 'polygon.geojson'\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(geo_json, f)\n",
    "        print(f'GeoJSON saved to {file_path}')\n",
    "\n",
    "\n",
    "\n",
    "# Attach the draw handler to the draw_control\n",
    "draw_control.on_draw(handle_draw)\n",
    "\n",
    "# Add the draw control to the map\n",
    "m.add_control(draw_control)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e887c5c-83a7-439d-be7b-0ba2a2516737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipyleaflet\n",
      "  Downloading ipyleaflet-0.17.4-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets<9,>=7.6.0 (from ipyleaflet)\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting traittypes<3,>=0.2.1 (from ipyleaflet)\n",
      "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting xyzservices>=2021.8.1 (from ipyleaflet)\n",
      "  Downloading xyzservices-2023.10.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting branca>=0.5.0 (from ipyleaflet)\n",
      "  Downloading branca-0.6.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from branca>=0.5.0->ipyleaflet) (3.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (0.1.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (5.9.0)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets<9,>=7.6.0->ipyleaflet)\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0.9 (from ipywidgets<9,>=7.6.0->ipyleaflet)\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->branca>=0.5.0->ipyleaflet) (2.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.16.0)\n",
      "Installing collected packages: xyzservices, widgetsnbextension, traittypes, jupyterlab-widgets, branca, ipywidgets, ipyleaflet\n",
      "Successfully installed branca-0.6.0 ipyleaflet-0.17.4 ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 traittypes-0.2.1 widgetsnbextension-4.0.9 xyzservices-2023.10.1\n",
      "Enabling notebook extension jupyter-leaflet/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipyleaflet\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295779bb-80a6-43b9-a9de-f9d71bf18a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708cc03-4ee1-42b9-939a-6ae13e9d14f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f771881-47ca-4503-8b79-400794048c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52dba5-6ba8-4e75-abcd-b4f0e7dd794a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f67c66a-4020-4709-8035-4bb6755fdf99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
